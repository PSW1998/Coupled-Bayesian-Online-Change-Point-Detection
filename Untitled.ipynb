{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ced5490d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_b/28jfj19121qf32rdzd8twc000000gn/T/ipykernel_19731/773199937.py:12: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=start, end=end)[\"Adj Close\"].dropna()\n",
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Adj Close'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Adj Close'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_b/28jfj19121qf32rdzd8twc000000gn/T/ipykernel_19731/773199937.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;31m# -----------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0mrets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2010-01-01\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0mparams_garch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_dcc_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_b/28jfj19121qf32rdzd8twc000000gn/T/ipykernel_19731/773199937.py\u001b[0m in \u001b[0;36mload_returns\u001b[0;34m(start, end)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_returns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2010-01-01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mtickers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"SPY\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TLT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtickers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Adj Close\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlog_prices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mrets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4099\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4101\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4102\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4158\u001b[0m         \u001b[0;31m# self.columns is a MultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4159\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4161\u001b[0m             \u001b[0mnew_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_maybe_to_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_level_indexer\u001b[0;34m(self, key, level, indexer)\u001b[0m\n\u001b[1;32m   3389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3390\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3391\u001b[0;31m             \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc_single_level_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lexsort_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_loc_single_level_index\u001b[0;34m(self, level_index, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlevel_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Adj Close'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from arch import arch_model\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Load SPY & TLT data, compute returns\n",
    "# -----------------------------\n",
    "def load_returns(start=\"2010-01-01\", end=None):\n",
    "    tickers = [\"SPY\", \"TLT\"]\n",
    "    data = yf.download(tickers, start=start, end=end)[\"Close\"].dropna()\n",
    "    log_prices = np.log(data)\n",
    "    rets = log_prices.diff().dropna()\n",
    "    rets.columns = tickers\n",
    "    return rets\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Fit univariate GARCH(1,1) to each series\n",
    "# -----------------------------\n",
    "def fit_garch_11(series):\n",
    "    \"\"\"\n",
    "    Fit GARCH(1,1) with zero mean and normal errors to a return series.\n",
    "    Returns:\n",
    "      res   : arch_model fit result\n",
    "      sigma : conditional std dev (np.array aligned with series)\n",
    "    \"\"\"\n",
    "    am = arch_model(series, mean=\"Zero\", vol=\"Garch\", p=1, q=1, dist=\"normal\")\n",
    "    res = am.fit(disp=\"off\")\n",
    "    sigma = res.conditional_volatility.values  # same scale as series\n",
    "    return res, sigma\n",
    "\n",
    "# -----------------------------\n",
    "# 3. DCC(1,1) negative log-likelihood\n",
    "# -----------------------------\n",
    "def dcc_nll(theta, Z):\n",
    "    \"\"\"\n",
    "    DCC(1,1) negative log-likelihood for standardized residuals Z (T x 2).\n",
    "\n",
    "    theta: unconstrained parameters (u, v) that we map to (a, b) via softmax:\n",
    "       e1 = exp(u), e2 = exp(v)\n",
    "       a  = e1 / (1 + e1 + e2)\n",
    "       b  = e2 / (1 + e1 + e2)\n",
    "       => a>0, b>0, a+b<1 automatically.\n",
    "    \"\"\"\n",
    "    T, k = Z.shape\n",
    "    # Map (theta[0], theta[1]) -> (a, b)\n",
    "    e1 = np.exp(theta[0])\n",
    "    e2 = np.exp(theta[1])\n",
    "    denom = 1.0 + e1 + e2\n",
    "    a = e1 / denom\n",
    "    b = e2 / denom\n",
    "\n",
    "    # Unconditional covariance of Z\n",
    "    Qbar = (Z.T @ Z) / T\n",
    "\n",
    "    # Initialize Q_0 as Qbar\n",
    "    Q = Qbar.copy()\n",
    "\n",
    "    nll = 0.0\n",
    "    for t in range(T):\n",
    "        z = Z[t].reshape(-1, 1)  # (2 x 1)\n",
    "\n",
    "        # DCC recursion\n",
    "        Q = (1.0 - a - b) * Qbar + a * (z @ z.T) + b * Q\n",
    "\n",
    "        # Convert Q_t to correlation matrix R_t\n",
    "        d = np.sqrt(np.diag(Q))\n",
    "        Dinv = np.diag(1.0 / d)\n",
    "        R = Dinv @ Q @ Dinv\n",
    "\n",
    "        # log-likelihood contribution: 0.5 [ log|R_t| + z_t' R_t^{-1} z_t ]\n",
    "        detR = np.linalg.det(R)\n",
    "        if detR <= 0:\n",
    "            # Penalize non-PD (should not happen with good params)\n",
    "            return 1e10\n",
    "\n",
    "        invR = np.linalg.inv(R)\n",
    "        nll += 0.5 * (np.log(detR) + (z.T @ invR @ z)[0, 0])\n",
    "\n",
    "    return nll\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Estimate DCC parameters and build H_t\n",
    "# -----------------------------\n",
    "def fit_dcc_2d(rets):\n",
    "    \"\"\"\n",
    "    Fit 2D DCC-GARCH(1,1) to returns DataFrame with columns [\"SPY\",\"TLT\"].\n",
    "\n",
    "    Returns:\n",
    "      params_garch: dict with GARCH fits for each asset\n",
    "      params_dcc  : dict with 'a', 'b'\n",
    "      sigma       : (T x 2) cond. std devs\n",
    "      R_t         : (T x 2 x 2) dynamic correlation matrices\n",
    "      H_t         : (T x 2 x 2) dynamic covariance matrices\n",
    "    \"\"\"\n",
    "    # Ensure correct order\n",
    "    rets = rets[[\"SPY\", \"TLT\"]].dropna()\n",
    "    T = len(rets)\n",
    "\n",
    "    # 4.1 Fit univariate GARCH(1,1)\n",
    "    res_spy, sigma_spy = fit_garch_11(rets[\"SPY\"])\n",
    "    res_tlt, sigma_tlt = fit_garch_11(rets[\"TLT\"])\n",
    "\n",
    "    sigma = np.column_stack([sigma_spy, sigma_tlt])  # T x 2\n",
    "\n",
    "    # 4.2 Standardized residuals\n",
    "    Z = rets.values / sigma  # T x 2\n",
    "\n",
    "    # 4.3 Estimate DCC parameters (a, b)\n",
    "    # Start with something like a ~ 0.01, b ~ 0.98\n",
    "    # We choose theta0 so that the softmax maps near there\n",
    "    # Roughly, small e1 and large e2 -> a small, b near 1.\n",
    "    theta0 = np.array([-4.0, 4.0])  # just a heuristic\n",
    "\n",
    "    opt = minimize(dcc_nll, theta0, args=(Z,), method=\"L-BFGS-B\")\n",
    "    if not opt.success:\n",
    "        print(\"Warning: DCC optimization did not fully converge:\", opt.message)\n",
    "\n",
    "    # Decode (a, b) from opt.x\n",
    "    e1 = np.exp(opt.x[0])\n",
    "    e2 = np.exp(opt.x[1])\n",
    "    denom = 1.0 + e1 + e2\n",
    "    a_hat = e1 / denom\n",
    "    b_hat = e2 / denom\n",
    "\n",
    "    # 4.4 Recompute Q_t, R_t, H_t using estimated (a_hat, b_hat)\n",
    "    Qbar = (Z.T @ Z) / T\n",
    "    Q = Qbar.copy()\n",
    "\n",
    "    R_t = np.zeros((T, 2, 2))\n",
    "    H_t = np.zeros((T, 2, 2))\n",
    "\n",
    "    for t in range(T):\n",
    "        z = Z[t].reshape(-1, 1)\n",
    "        Q = (1.0 - a_hat - b_hat) * Qbar + a_hat * (z @ z.T) + b_hat * Q\n",
    "\n",
    "        d = np.sqrt(np.diag(Q))\n",
    "        Dinv = np.diag(1.0 / d)\n",
    "        R = Dinv @ Q @ Dinv\n",
    "\n",
    "        R_t[t] = R\n",
    "\n",
    "        # Full covariance H_t = D_t R_t D_t\n",
    "        D_t = np.diag(sigma[t])\n",
    "        H_t[t] = D_t @ R @ D_t\n",
    "\n",
    "    params_garch = {\n",
    "        \"SPY\": res_spy,\n",
    "        \"TLT\": res_tlt,\n",
    "    }\n",
    "    params_dcc = {\n",
    "        \"a\": a_hat,\n",
    "        \"b\": b_hat,\n",
    "        \"opt_result\": opt,\n",
    "    }\n",
    "\n",
    "    return params_garch, params_dcc, sigma, R_t, H_t\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Run the whole thing\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    rets = load_returns(start=\"2010-01-01\")\n",
    "    params_garch, params_dcc, sigma, R_t, H_t = fit_dcc_2d(rets)\n",
    "\n",
    "    print(\"\\nUnivariate GARCH(1,1) summary:\")\n",
    "    print(\"SPY GARCH params:\")\n",
    "    print(params_garch[\"SPY\"].params)\n",
    "    print(\"\\nTLT GARCH params:\")\n",
    "    print(params_garch[\"TLT\"].params)\n",
    "\n",
    "    print(\"\\nEstimated DCC parameters:\")\n",
    "    print(\"a (correlation ARCH term) :\", params_dcc[\"a\"])\n",
    "    print(\"b (correlation GARCH term):\", params_dcc[\"b\"])\n",
    "\n",
    "    # Example: last estimated correlation between SPY and TLT\n",
    "    last_rho = R_t[-1, 0, 1]\n",
    "    print(\"\\nLast estimated correlation ρ_T(SPY, TLT):\", last_rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c2fcb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 0. Utility: simple gradient descent with finite differences\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def gradient_descent(func, theta0, lr=1e-3, max_iter=2000, tol=1e-6, verbose=False):\n",
    "    \"\"\"\n",
    "    Very simple gradient descent minimizer using central finite differences.\n",
    "\n",
    "    func    : function(theta) -> scalar\n",
    "    theta0  : initial parameter vector (1D numpy array)\n",
    "    lr      : learning rate\n",
    "    max_iter: maximum iterations\n",
    "    tol     : stop if ||grad|| < tol\n",
    "    \"\"\"\n",
    "    theta = theta0.astype(float).copy()\n",
    "    eps = 1e-5\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        # finite-difference gradient\n",
    "        grad = np.zeros_like(theta)\n",
    "        f0 = func(theta)\n",
    "        for i in range(len(theta)):\n",
    "            e = np.zeros_like(theta)\n",
    "            e[i] = 1.0\n",
    "            f_plus = func(theta + eps * e)\n",
    "            f_minus = func(theta - eps * e)\n",
    "            grad[i] = (f_plus - f_minus) / (2.0 * eps)\n",
    "\n",
    "        grad_norm = np.linalg.norm(grad)\n",
    "        if verbose and (it % 200 == 0):\n",
    "            print(f\"[GD] iter={it}, f={f0:.6f}, ||grad||={grad_norm:.4e}\")\n",
    "\n",
    "        if grad_norm < tol:\n",
    "            break\n",
    "\n",
    "        theta -= lr * grad\n",
    "\n",
    "    return theta, func(theta)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Univariate GARCH(1,1) from scratch (Gaussian QML)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def garch11_nll(theta, y):\n",
    "    \"\"\"\n",
    "    Negative log-likelihood for GARCH(1,1) with Gaussian innovations.\n",
    "\n",
    "    Parametrization:\n",
    "      theta = [a, b, c]  (unconstrained)\n",
    "      omega = exp(a) > 0\n",
    "      (alpha, beta) in (0,1) with alpha + beta < 1 via:\n",
    "         u = logistic(b)\n",
    "         v = logistic(c)\n",
    "         alpha = u * (1 - v)\n",
    "         beta  = u * v\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    T = len(y)\n",
    "\n",
    "    a, b, c = theta\n",
    "    omega = np.exp(a)\n",
    "\n",
    "    u = 1.0 / (1.0 + np.exp(-b))   # in (0,1)\n",
    "    v = 1.0 / (1.0 + np.exp(-c))   # in (0,1)\n",
    "    alpha = u * (1.0 - v)\n",
    "    beta  = u * v\n",
    "    # alpha + beta = u < 1, guaranteed\n",
    "\n",
    "    sigma2 = np.empty(T)\n",
    "    # initialize with unconditional variance\n",
    "    sigma2[0] = omega / (1.0 - alpha - beta + 1e-6)\n",
    "    for t in range(1, T):\n",
    "        sigma2[t] = omega + alpha * y[t-1]**2 + beta * sigma2[t-1]\n",
    "\n",
    "    # Gaussian negative log-likelihood (constant dropped)\n",
    "    return 0.5 * np.sum(np.log(sigma2) + (y**2) / sigma2)\n",
    "\n",
    "\n",
    "def fit_garch11(y, lr=1e-3, max_iter=3000, verbose=False):\n",
    "    \"\"\"\n",
    "    Fit a univariate GARCH(1,1) to y using gradient descent on the NLL.\n",
    "\n",
    "    Returns:\n",
    "      omega_hat, alpha_hat, beta_hat, sigma2_hat\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    y = y - y.mean()  # center\n",
    "\n",
    "    # crude initial guesses\n",
    "    var_y = np.var(y)\n",
    "    omega0 = 0.1 * var_y\n",
    "    alpha0 = 0.05\n",
    "    beta0  = 0.9 - alpha0  # persistence ~0.9\n",
    "\n",
    "    # map to unconstrained a,b,c\n",
    "    a0 = np.log(omega0)\n",
    "\n",
    "    # inverse of alpha = u(1-v), beta = uv is messy; just pick a, b, c s.t. u, v close\n",
    "    # we can pick u0 = alpha0 + beta0, v0 = beta0 / (alpha0 + beta0)\n",
    "    u0 = alpha0 + beta0\n",
    "    v0 = beta0 / u0\n",
    "    b0 = np.log(u0 / (1.0 - u0))\n",
    "    c0 = np.log(v0 / (1.0 - v0))\n",
    "\n",
    "    theta0 = np.array([a0, b0, c0], dtype=float)\n",
    "\n",
    "    theta_hat, nll_min = gradient_descent(\n",
    "        lambda th: garch11_nll(th, y),\n",
    "        theta0,\n",
    "        lr=lr,\n",
    "        max_iter=max_iter,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    a_hat, b_hat, c_hat = theta_hat\n",
    "    omega_hat = np.exp(a_hat)\n",
    "\n",
    "    u_hat = 1.0 / (1.0 + np.exp(-b_hat))\n",
    "    v_hat = 1.0 / (1.0 + np.exp(-c_hat))\n",
    "    alpha_hat = u_hat * (1.0 - v_hat)\n",
    "    beta_hat  = u_hat * v_hat\n",
    "\n",
    "    # build sigma2 path with estimated params\n",
    "    T = len(y)\n",
    "    sigma2_hat = np.empty(T)\n",
    "    sigma2_hat[0] = omega_hat / (1.0 - alpha_hat - beta_hat + 1e-6)\n",
    "    for t in range(1, T):\n",
    "        sigma2_hat[t] = omega_hat + alpha_hat * y[t-1]**2 + beta_hat * sigma2_hat[t-1]\n",
    "\n",
    "    return omega_hat, alpha_hat, beta_hat, sigma2_hat\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. DCC(1,1) for 2D standardized residuals\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def dcc_nll(theta, Z):\n",
    "    \"\"\"\n",
    "    DCC(1,1) negative log-likelihood for standardized residuals Z (T x 2).\n",
    "\n",
    "    Parametrization:\n",
    "      theta = [u, v] unconstrained.\n",
    "      a, b are mapped via \"softmax\" so that:\n",
    "         a = e1 / (1 + e1 + e2)\n",
    "         b = e2 / (1 + e1 + e2)\n",
    "      => a>0, b>0, a + b < 1.\n",
    "    \"\"\"\n",
    "    Z = np.asarray(Z, dtype=float)\n",
    "    T, k = Z.shape\n",
    "    assert k == 2, \"This DCC implementation is for 2D only.\"\n",
    "\n",
    "    # map to (a, b)\n",
    "    e1 = np.exp(theta[0])\n",
    "    e2 = np.exp(theta[1])\n",
    "    denom = 1.0 + e1 + e2\n",
    "    a = e1 / denom\n",
    "    b = e2 / denom\n",
    "\n",
    "    # unconditional covariance of Z\n",
    "    Qbar = (Z.T @ Z) / T\n",
    "    Q = Qbar.copy()\n",
    "\n",
    "    nll = 0.0\n",
    "    for t in range(T):\n",
    "        z = Z[t].reshape(-1, 1)  # (2 x 1)\n",
    "        # DCC recursion\n",
    "        Q = (1.0 - a - b) * Qbar + a * (z @ z.T) + b * Q\n",
    "\n",
    "        # normalize to correlation matrix\n",
    "        d = np.sqrt(np.diag(Q))\n",
    "        Dinv = np.diag(1.0 / d)\n",
    "        R = Dinv @ Q @ Dinv\n",
    "\n",
    "        detR = np.linalg.det(R)\n",
    "        if detR <= 0:\n",
    "            return 1e10  # penalize non-PD\n",
    "\n",
    "        invR = np.linalg.inv(R)\n",
    "        nll += 0.5 * (np.log(detR) + (z.T @ invR @ z)[0, 0])\n",
    "\n",
    "    return nll\n",
    "\n",
    "\n",
    "def fit_dcc_2d(spy_ret, tlt_ret, lr_garch=1e-3, lr_dcc=1e-3,\n",
    "               max_iter_garch=3000, max_iter_dcc=2000,\n",
    "               verbose=False):\n",
    "    \"\"\"\n",
    "    Fit 2D DCC-GARCH(1,1) to SPY and TLT return series.\n",
    "\n",
    "    Inputs:\n",
    "      spy_ret, tlt_ret : 1D numpy arrays of returns (same length)\n",
    "\n",
    "    Returns:\n",
    "      params_garch : dict with univariate GARCH params & sigma paths\n",
    "      params_dcc   : dict with DCC params\n",
    "      Z            : standardized residuals (T x 2)\n",
    "      R_t          : dynamic correlation matrices (T x 2 x 2)\n",
    "      H_t          : dynamic covariance matrices (T x 2 x 2)\n",
    "    \"\"\"\n",
    "    spy_ret = np.asarray(spy_ret, dtype=float)\n",
    "    tlt_ret = np.asarray(tlt_ret, dtype=float)\n",
    "    assert len(spy_ret) == len(tlt_ret), \"Series must have same length.\"\n",
    "    T = len(spy_ret)\n",
    "\n",
    "    # --- 1. Fit univariate GARCH(1,1) to each ---\n",
    "    omega1, alpha1, beta1, sigma2_1 = fit_garch11(spy_ret, lr=lr_garch,\n",
    "                                                  max_iter=max_iter_garch,\n",
    "                                                  verbose=verbose)\n",
    "    omega2, alpha2, beta2, sigma2_2 = fit_garch11(tlt_ret, lr=lr_garch,\n",
    "                                                  max_iter=max_iter_garch,\n",
    "                                                  verbose=verbose)\n",
    "\n",
    "    sigma1 = np.sqrt(sigma2_1)\n",
    "    sigma2 = np.sqrt(sigma2_2)\n",
    "\n",
    "    # standardized residuals\n",
    "    z1 = (spy_ret - spy_ret.mean()) / sigma1\n",
    "    z2 = (tlt_ret - tlt_ret.mean()) / sigma2\n",
    "    Z = np.column_stack([z1, z2])  # T x 2\n",
    "\n",
    "    # --- 2. Fit DCC(1,1) on Z ---\n",
    "    theta0 = np.array([-4.0, 4.0])  # heuristic start (a small, b near 1)\n",
    "\n",
    "    theta_hat, dcc_nll_min = gradient_descent(\n",
    "        lambda th: dcc_nll(th, Z),\n",
    "        theta0,\n",
    "        lr=lr_dcc,\n",
    "        max_iter=max_iter_dcc,\n",
    "        verbose=verbose\n",
    "    )\n",
    "\n",
    "    e1 = np.exp(theta_hat[0])\n",
    "    e2 = np.exp(theta_hat[1])\n",
    "    denom = 1.0 + e1 + e2\n",
    "    a_hat = e1 / denom\n",
    "    b_hat = e2 / denom\n",
    "\n",
    "    # --- 3. Reconstruct Q_t, R_t, H_t ---\n",
    "    Qbar = (Z.T @ Z) / T\n",
    "    Q = Qbar.copy()\n",
    "\n",
    "    R_t = np.zeros((T, 2, 2))\n",
    "    H_t = np.zeros((T, 2, 2))\n",
    "\n",
    "    for t in range(T):\n",
    "        z = Z[t].reshape(-1, 1)\n",
    "        Q = (1.0 - a_hat - b_hat) * Qbar + a_hat * (z @ z.T) + b_hat * Q\n",
    "\n",
    "        d = np.sqrt(np.diag(Q))\n",
    "        Dinv = np.diag(1.0 / d)\n",
    "        R = Dinv @ Q @ Dinv\n",
    "        R_t[t] = R\n",
    "\n",
    "        D_t = np.diag([sigma1[t], sigma2[t]])\n",
    "        H_t[t] = D_t @ R @ D_t\n",
    "\n",
    "    params_garch = {\n",
    "        \"SPY\": {\n",
    "            \"omega\": omega1,\n",
    "            \"alpha\": alpha1,\n",
    "            \"beta\": beta1,\n",
    "            \"sigma2\": sigma2_1\n",
    "        },\n",
    "        \"TLT\": {\n",
    "            \"omega\": omega2,\n",
    "            \"alpha\": alpha2,\n",
    "            \"beta\": beta2,\n",
    "            \"sigma2\": sigma2_2\n",
    "        }\n",
    "    }\n",
    "\n",
    "    params_dcc = {\n",
    "        \"a\": a_hat,\n",
    "        \"b\": b_hat,\n",
    "        \"nll\": dcc_nll_min\n",
    "    }\n",
    "\n",
    "    return params_garch, params_dcc, Z, R_t, H_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e05fd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_b/28jfj19121qf32rdzd8twc000000gn/T/ipykernel_19731/1470862187.py:2: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(tickers, start=\"2021-01-01\", end=\"2025-12-31\")[\"Close\"].dropna()\n",
      "[*********************100%***********************]  2 of 2 completed\n"
     ]
    }
   ],
   "source": [
    "tickers = [\"SPY\", \"TLT\"]\n",
    "data = yf.download(tickers, start=\"2021-01-01\", end=\"2025-12-31\")[\"Close\"].dropna()\n",
    "log_prices = np.log(data)\n",
    "rets = log_prices.diff().dropna()\n",
    "rets.columns = tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "caa23a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SPY</th>\n",
       "      <th>TLT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-01-05</th>\n",
       "      <td>0.006864</td>\n",
       "      <td>-0.007454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-06</th>\n",
       "      <td>0.005961</td>\n",
       "      <td>-0.020742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-07</th>\n",
       "      <td>0.014748</td>\n",
       "      <td>-0.008854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-08</th>\n",
       "      <td>0.005682</td>\n",
       "      <td>-0.003233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-01-11</th>\n",
       "      <td>-0.006764</td>\n",
       "      <td>-0.001654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-24</th>\n",
       "      <td>0.011054</td>\n",
       "      <td>0.004220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-26</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>-0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-27</th>\n",
       "      <td>-0.010582</td>\n",
       "      <td>-0.008232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-30</th>\n",
       "      <td>-0.011477</td>\n",
       "      <td>0.008005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-12-31</th>\n",
       "      <td>-0.003645</td>\n",
       "      <td>-0.005368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SPY       TLT\n",
       "Date                          \n",
       "2021-01-05  0.006864 -0.007454\n",
       "2021-01-06  0.005961 -0.020742\n",
       "2021-01-07  0.014748 -0.008854\n",
       "2021-01-08  0.005682 -0.003233\n",
       "2021-01-11 -0.006764 -0.001654\n",
       "...              ...       ...\n",
       "2024-12-24  0.011054  0.004220\n",
       "2024-12-26  0.000067 -0.000569\n",
       "2024-12-27 -0.010582 -0.008232\n",
       "2024-12-30 -0.011477  0.008005\n",
       "2024-12-31 -0.003645 -0.005368\n",
       "\n",
       "[1004 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de708f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spy_ret and tlt_ret: 1D numpy arrays with daily log returns\n",
    "\n",
    "params_garch, params_dcc, Z, R_t, H_t = fit_dcc_2d(spy_ret, tlt_ret,\n",
    "                                                   lr_garch=1e-3,\n",
    "                                                   lr_dcc=1e-3,\n",
    "                                                   max_iter_garch=3000,\n",
    "                                                   max_iter_dcc=2000,\n",
    "                                                   verbose=True)\n",
    "\n",
    "print(\"SPY GARCH params:\", params_garch[\"SPY\"][\"omega\"],\n",
    "                          params_garch[\"SPY\"][\"alpha\"],\n",
    "                          params_garch[\"SPY\"][\"beta\"])\n",
    "\n",
    "print(\"TLT GARCH params:\", params_garch[\"TLT\"][\"omega\"],\n",
    "                          params_garch[\"TLT\"][\"alpha\"],\n",
    "                          params_garch[\"TLT\"][\"beta\"])\n",
    "\n",
    "print(\"DCC params: a =\", params_dcc[\"a\"], \", b =\", params_dcc[\"b\"])\n",
    "\n",
    "# Last estimated correlation between SPY and TLT:\n",
    "last_rho = R_t[-1, 0, 1]\n",
    "print(\"Last ρ(SPY, TLT):\", last_rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51bcd8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# --- helper: get sigma^2 path from ARCH(1) params and data ---\n",
    "\n",
    "def arch1_sigma2(y, omega, alpha):\n",
    "    \"\"\"\n",
    "    Given y_t and ARCH(1) params (omega, alpha) from fitarch1,\n",
    "    compute the conditional variance path sigma2_t.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    T = len(y)\n",
    "    sigma2 = np.empty(T)\n",
    "    # init with unconditional variance\n",
    "    sigma2[0] = omega / (1.0 - alpha + 1e-6)\n",
    "    for t in range(1, T):\n",
    "        sigma2[t] = omega + alpha * y[t-1]**2\n",
    "    return sigma2\n",
    "\n",
    "# --- DCC(1,1) negative log-likelihood for 2D Z ---\n",
    "\n",
    "def dcc_nll(theta, Z):\n",
    "    \"\"\"\n",
    "    DCC(1,1) negative log-likelihood for standardized residuals Z (T x 2).\n",
    "\n",
    "    theta = [u, v] unconstrained.\n",
    "    We map to (a, b) via a softmax to ensure a>0, b>0, a+b<1:\n",
    "        e1 = exp(u), e2 = exp(v)\n",
    "        a  = e1 / (1 + e1 + e2)\n",
    "        b  = e2 / (1 + e1 + e2)\n",
    "    \"\"\"\n",
    "    Z = np.asarray(Z, dtype=float)\n",
    "    T, k = Z.shape\n",
    "    assert k == 2, \"This DCC implementation is for 2D only.\"\n",
    "\n",
    "    # map (theta[0], theta[1]) -> (a, b)\n",
    "    e1 = np.exp(theta[0])\n",
    "    e2 = np.exp(theta[1])\n",
    "    denom = 1.0 + e1 + e2\n",
    "    a = e1 / denom\n",
    "    b = e2 / denom\n",
    "\n",
    "    # unconditional covariance of Z\n",
    "    Qbar = (Z.T @ Z) / T\n",
    "    Q = Qbar.copy()\n",
    "\n",
    "    nll = 0.0\n",
    "    for t in range(T):\n",
    "        z = Z[t].reshape(-1, 1)  # (2 x 1)\n",
    "\n",
    "        # DCC recursion\n",
    "        Q = (1.0 - a - b) * Qbar + a * (z @ z.T) + b * Q\n",
    "\n",
    "        # normalize to correlation matrix\n",
    "        d = np.sqrt(np.diag(Q))\n",
    "        Dinv = np.diag(1.0 / d)\n",
    "        R = Dinv @ Q @ Dinv\n",
    "\n",
    "        detR = np.linalg.det(R)\n",
    "        if detR <= 0:\n",
    "            return 1e10  # penalize non-PD\n",
    "\n",
    "        invR = np.linalg.inv(R)\n",
    "        nll += 0.5 * (np.log(detR) + (z.T @ invR @ z)[0, 0])\n",
    "\n",
    "    return nll\n",
    "\n",
    "# --- main wrapper: DCC-ARCH(1) for your `rets` DataFrame ---\n",
    "\n",
    "def fit_dcc_arch1_2d(rets, lr_dcc=1e-3, max_iter_dcc=2000):\n",
    "    \"\"\"\n",
    "    rets: DataFrame with columns [\"SPY\",\"TLT\"] as you defined:\n",
    "        tickers = [\"SPY\", \"TLT\"]\n",
    "        data = yf.download(tickers, start=\"2021-01-01\", end=\"2025-12-31\")[\"Close\"].dropna()\n",
    "        log_prices = np.log(data)\n",
    "        rets = log_prices.diff().dropna()\n",
    "        rets.columns = tickers\n",
    "    Uses your existing `fitarch1` for the univariate parts.\n",
    "    \"\"\"\n",
    "    rets = rets[[\"SPY\", \"TLT\"]].dropna()\n",
    "    spy = rets[\"SPY\"].to_numpy()\n",
    "    tlt = rets[\"TLT\"].to_numpy()\n",
    "    T = len(spy)\n",
    "\n",
    "    # --- 1. Fit univariate ARCH(1) to SPY and TLT using YOUR fitarch1 ---\n",
    "    res_spy = fitarch1(spy)\n",
    "    res_tlt = fitarch1(tlt)\n",
    "\n",
    "    omega1, alpha1 = res_spy[\"omega\"], res_spy[\"alpha\"]\n",
    "    omega2, alpha2 = res_tlt[\"omega\"], res_tlt[\"alpha\"]\n",
    "\n",
    "    # build sigma^2 paths\n",
    "    sigma2_1 = arch1_sigma2(spy, omega1, alpha1)\n",
    "    sigma2_2 = arch1_sigma2(tlt, omega2, alpha2)\n",
    "\n",
    "    sigma1 = np.sqrt(sigma2_1)\n",
    "    sigma2 = np.sqrt(sigma2_2)\n",
    "\n",
    "    # standardized residuals (use centered returns; ARCH is already on centered y in your fit)\n",
    "    z1 = (spy - spy.mean()) / sigma1\n",
    "    z2 = (tlt - tlt.mean()) / sigma2\n",
    "    Z = np.column_stack([z1, z2])  # T x 2\n",
    "\n",
    "    # --- 2. Fit DCC(1,1) over Z using your gradient_descent ---\n",
    "    theta0 = np.array([-4.0, 4.0])  # heuristic start (a small, b near 1)\n",
    "    theta_hat, nll_dcc_min = gradient_descent(\n",
    "        lambda th: dcc_nll(th, Z),\n",
    "        theta0,\n",
    "        lr=lr_dcc,\n",
    "        max_iter=max_iter_dcc\n",
    "    )\n",
    "\n",
    "    e1 = np.exp(theta_hat[0])\n",
    "    e2 = np.exp(theta_hat[1])\n",
    "    denom = 1.0 + e1 + e2\n",
    "    a_hat = e1 / denom\n",
    "    b_hat = e2 / denom\n",
    "\n",
    "    # --- 3. Reconstruct Q_t, R_t, H_t ---\n",
    "    Qbar = (Z.T @ Z) / T\n",
    "    Q = Qbar.copy()\n",
    "\n",
    "    R_t = np.zeros((T, 2, 2))\n",
    "    H_t = np.zeros((T, 2, 2))\n",
    "\n",
    "    for t in range(T):\n",
    "        z = Z[t].reshape(-1, 1)\n",
    "        Q = (1.0 - a_hat - b_hat) * Qbar + a_hat * (z @ z.T) + b_hat * Q\n",
    "\n",
    "        d = np.sqrt(np.diag(Q))\n",
    "        Dinv = np.diag(1.0 / d)\n",
    "        R = Dinv @ Q @ Dinv\n",
    "        R_t[t] = R\n",
    "\n",
    "        D_t = np.diag([sigma1[t], sigma2[t]])\n",
    "        H_t[t] = D_t @ R @ D_t\n",
    "\n",
    "    params_garch = {\n",
    "        \"SPY\": {\"omega\": omega1, \"alpha\": alpha1, \"sigma2\": sigma2_1},\n",
    "        \"TLT\": {\"omega\": omega2, \"alpha\": alpha2, \"sigma2\": sigma2_2},\n",
    "    }\n",
    "    params_dcc = {\"a\": a_hat, \"b\": b_hat, \"nll\": nll_dcc_min}\n",
    "\n",
    "    return params_garch, params_dcc, Z, R_t, H_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28f10368",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fitarch1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_b/28jfj19121qf32rdzd8twc000000gn/T/ipykernel_19731/1389923877.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparams_garch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_dcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_dcc_arch1_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SPY ARCH(1):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_garch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SPY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"omega\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_garch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SPY\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TLT ARCH(1):\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_garch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TLT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"omega\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams_garch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TLT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"alpha\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/_b/28jfj19121qf32rdzd8twc000000gn/T/ipykernel_19731/2490993229.py\u001b[0m in \u001b[0;36mfit_dcc_arch1_2d\u001b[0;34m(rets, lr_dcc, max_iter_dcc)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# --- 1. Fit univariate ARCH(1) to SPY and TLT using YOUR fitarch1 ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mres_spy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitarch1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0mres_tlt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitarch1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtlt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fitarch1' is not defined"
     ]
    }
   ],
   "source": [
    "params_garch, params_dcc, Z, R_t, H_t = fit_dcc_arch1_2d(rets)\n",
    "\n",
    "print(\"SPY ARCH(1):\", params_garch[\"SPY\"][\"omega\"], params_garch[\"SPY\"][\"alpha\"])\n",
    "print(\"TLT ARCH(1):\", params_garch[\"TLT\"][\"omega\"], params_garch[\"TLT\"][\"alpha\"])\n",
    "\n",
    "print(\"DCC params: a =\", params_dcc[\"a\"], \", b =\", params_dcc[\"b\"])\n",
    "\n",
    "# Last estimated correlation between SPY and TLT:\n",
    "last_rho = R_t[-1, 0, 1]\n",
    "print(\"Last correlation ρ_T(SPY, TLT):\", last_rho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5567d78b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
