{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00287234-1a4f-4697-b71c-86dd1911b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def add_intercept(X):\n",
    "    n = X.shape[0]\n",
    "    intercept = np.ones((n,1))\n",
    "    return np.hstack([intercept,X])\n",
    "\n",
    "def ols_fit(X,y):\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y).reshape(-1,1)\n",
    "\n",
    "    X_design = add_intercept(X)\n",
    "    XtX= X_design.T @ X_design\n",
    "    Xty = X_design.T @ y\n",
    "\n",
    "    beta_hat = np.linalg.solve(XtX,Xty)\n",
    "    return beta_hat.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21eb58d0-30df-4df0-90a5-0dfa300f4080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ridge_regression(X, y, lam, fit_intercept=True):\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    y = np.asarray(y, dtype=float).reshape(-1)\n",
    "    n, p = X.shape\n",
    "\n",
    "    if fit_intercept:\n",
    "        X_mean = X.mean(axis=0)\n",
    "        y_mean = y.mean()\n",
    "\n",
    "        Xc = X - X_mean\n",
    "        yc = y - y_mean\n",
    "    else:\n",
    "        X_mean = np.zeros(p)\n",
    "        y_mean = 0.0\n",
    "        Xc = X\n",
    "        yc = y\n",
    "\n",
    "    XtX = Xc.T @ Xc             \n",
    "    A = XtX + lam * np.eye(p)    \n",
    "\n",
    "\n",
    "    Xty = Xc.T @ yc          \n",
    "\n",
    "\n",
    "    beta = np.linalg.solve(A, Xty)\n",
    "\n",
    "    beta0 = y_mean - np.dot(X_mean, beta) if fit_intercept else 0.0\n",
    "\n",
    "    return beta0, beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f78c51bc-9a08-4b0d-9465-c21a173b00b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated intercept: 3.012298611642308\n",
      "Estimated beta:      [ 2.95140621  0.05151579 -1.96218561 -0.01272196 -0.01844992]\n"
     ]
    }
   ],
   "source": [
    "# Fake data\n",
    "rng = np.random.default_rng(0)\n",
    "n, p = 1000, 5\n",
    "X = rng.normal(size=(n, p))\n",
    "true_beta = np.array([3.0, 0.0, -2.0, 0.0, 0.0])\n",
    "y = X @ true_beta + 3.0 + rng.normal(scale=1.0, size=n)  # intercept = 3\n",
    "\n",
    "lam = 10.0  # try different values: 0 (OLS), 1, 10, 100\n",
    "beta0_hat, beta_hat = ridge_regression(X, y, lam)\n",
    "\n",
    "print(\"Estimated intercept:\", beta0_hat)\n",
    "print(\"Estimated beta:     \", beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c08f656-2129-44e7-aa6c-7b05e0ad8c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.041401729930683806\n",
      "Coefficients: [ 3.01549672e+00 -2.70205187e-02 -1.98687045e+00  1.45686264e-03\n",
      "  4.21062650e-02]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def soft_threshold(z, lam):\n",
    "    \"\"\"Soft-thresholding operator S(z, lam).\"\"\"\n",
    "    if z > lam:\n",
    "        return z - lam\n",
    "    elif z < -lam:\n",
    "        return z + lam\n",
    "    else:\n",
    "        return 0.0\n",
    "\n",
    "def lasso_coordinate_descent(X, y, lam, max_iter=1000, tol=1e-6):\n",
    "    \"\"\"\n",
    "    LASSO regression via coordinate descent.\n",
    "\n",
    "    Objective:\n",
    "        (1/(2n)) * ||y - beta0 - X beta||^2 + lam * ||beta||_1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : (n, p) array_like\n",
    "        Predictor matrix.\n",
    "    y : (n,) or (n, 1) array_like\n",
    "        Response vector.\n",
    "    lam : float\n",
    "        L1 penalty (lambda).\n",
    "    max_iter : int\n",
    "        Maximum number of coordinate descent sweeps.\n",
    "    tol : float\n",
    "        Convergence tolerance on coefficients.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    beta0 : float\n",
    "        Intercept term.\n",
    "    beta : (p,) numpy array\n",
    "        Coefficient vector.\n",
    "    \"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    y = np.asarray(y, dtype=float).reshape(-1)\n",
    "\n",
    "    n, p = X.shape\n",
    "\n",
    "    # ----- Standardize X and center y -----\n",
    "    # Means and std for each column\n",
    "    X_mean = X.mean(axis=0)\n",
    "    X_std = X.std(axis=0, ddof=0)\n",
    "\n",
    "    # Avoid divide-by-zero if a column is constant\n",
    "    X_std[X_std == 0.0] = 1.0\n",
    "\n",
    "    Xs = (X - X_mean) / X_std  # standardized predictors\n",
    "    y_mean = y.mean()\n",
    "    ys = y - y_mean            # centered response\n",
    "\n",
    "    # We’ll fit ys ~ Xs beta (intercept is 0 in standardized space)\n",
    "    # Intercept is recovered afterwards from means.\n",
    "\n",
    "    # Precompute squared norms of columns of Xs\n",
    "    X_col_sqnorm = np.sum(Xs**2, axis=0)  # shape (p,)\n",
    "\n",
    "    # Initialize coefficients\n",
    "    beta = np.zeros(p)\n",
    "    # Residual r = ys - Xs @ beta  (start with beta=0 => r = ys)\n",
    "    r = ys.copy()\n",
    "\n",
    "    for it in range(max_iter):\n",
    "        beta_old = beta.copy()\n",
    "\n",
    "        for j in range(p):\n",
    "            # Add back current feature's contribution to residual\n",
    "            # r currently = ys - Xs @ beta\n",
    "            # We want partial residual excluding feature j:\n",
    "            # r_j = ys - sum_{k != j} Xs[:,k] beta[k]\n",
    "            #     = r + Xs[:,j] * beta[j]\n",
    "            r_j = r + Xs[:, j] * beta[j]\n",
    "\n",
    "            # Compute rho_j = sum_i X_ij * r_j_i\n",
    "            rho_j = np.dot(Xs[:, j], r_j)\n",
    "\n",
    "            # Coordinate update with soft-thresholding\n",
    "            # Note: no 1/n here; you can absorb that into lam if desired.\n",
    "            beta_j_new = soft_threshold(rho_j, lam) / X_col_sqnorm[j]\n",
    "\n",
    "            # Update residual to reflect new beta_j\n",
    "            r = r_j - Xs[:, j] * beta_j_new\n",
    "            beta[j] = beta_j_new\n",
    "\n",
    "        # Check convergence\n",
    "        max_change = np.max(np.abs(beta - beta_old))\n",
    "        if max_change < tol:\n",
    "            break\n",
    "\n",
    "    # Un-standardize coefficients and recover intercept\n",
    "    # ys = y - y_mean, Xs = (X - X_mean) / X_std\n",
    "    # model in original scale: y ≈ beta0 + X @ beta_orig\n",
    "    beta_orig = beta / X_std\n",
    "    beta0 = y_mean - np.dot(beta_orig, X_mean)\n",
    "\n",
    "    return beta0, beta_orig\n",
    "# Fake data with some true sparse beta\n",
    "rng = np.random.default_rng(0)\n",
    "n, p = 200, 5\n",
    "\n",
    "X = rng.normal(size=(n, p))\n",
    "true_beta = np.array([3.0, 0.0, -2.0, 0.0, 0.0])\n",
    "y = X @ true_beta + rng.normal(scale=1.0, size=n)\n",
    "\n",
    "lam = 10\n",
    "beta0_hat, beta_hat = lasso_coordinate_descent(X, y, lam)\n",
    "\n",
    "print(\"Intercept:\", beta0_hat)\n",
    "print(\"Coefficients:\", beta_hat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8257440-515f-43a3-ad7a-7900ca63acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectedvalue(j):\n",
    "    if j == 1:\n",
    "        return 3.5\n",
    "    return 1/6*max(expectedvalue(j-1),6)+1/6*max(expectedvalue(j-1),1)+1/6*max(expectedvalue(j-1),5)+1/6*max(expectedvalue(j-1),4)+1/6*max(expectedvalue(j-1),3)+1/6*max(expectedvalue(j-1),2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7eff0a2-fdc8-4ef4-a70e-7f17903c96c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.12962962962963"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expectedvalue(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d87de9b4-7623-4f4a-a5b3-f9d4b971bc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expectedvalue(j):\n",
    "    ev = 3.5  # base case for j = 1\n",
    "    for _ in range(2, j + 1):\n",
    "        ev = sum(max(ev, face) for face in range(1, 7)) / 6\n",
    "    return ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e632b-813a-43e4-a660-ac7dbebeacab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
